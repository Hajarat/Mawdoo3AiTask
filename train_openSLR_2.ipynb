{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender classification with openSLR - 2D CNN\n",
    "This notebook contains my (Hassan Hajarat) attempt in training the \"Open Speech & Language Resources\" dataset using a 2D convolutional neural network as an attempt to produce a gender classifier.<br>\n",
    "Done with the help of: https://medium.com/@mikesmales/sound-classification-using-deep-learning-8bc2aa1990b7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm.contrib import tzip\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.getcwd() + \"/raw-audio-gender-classification\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since I already indexed the data in the previous model build, I can import the indexes here\n",
    "length = 48000 # First 3 seconds of each flac file (that's just how the files were saved for the first model)\n",
    "train_subsets = ['train-clean-100']\n",
    "test_subsets = ['dev-clean']\n",
    "\n",
    "train_cached_id_to_filepath_location = PATH + '/data/LibriSpeech__datasetid_to_filepath__subsets={}__length={}.json'.format(\n",
    "            train_subsets, length)\n",
    "\n",
    "train_cached_id_to_sex_location = PATH + '/data/LibriSpeech__datasetid_to_sex__subsets={}__length={}.json'.format(\n",
    "            train_subsets, length)\n",
    "\n",
    "test_cached_id_to_filepath_location = PATH + '/data/LibriSpeech__datasetid_to_filepath__subsets={}__length={}.json'.format(\n",
    "            test_subsets, length)\n",
    "\n",
    "test_cached_id_to_sex_location = PATH + '/data/LibriSpeech__datasetid_to_sex__subsets={}__length={}.json'.format(\n",
    "            test_subsets, length)\n",
    "\n",
    "with open(train_cached_id_to_filepath_location) as f:\n",
    "    train_datasetid_to_filepath = json.load(f)\n",
    "    \n",
    "with open(train_cached_id_to_sex_location) as f:\n",
    "    train_datasetid_to_sex = json.load(f)\n",
    "\n",
    "with open(test_cached_id_to_filepath_location) as f:\n",
    "    test_datasetid_to_filepath = json.load(f)\n",
    "    \n",
    "with open(test_cached_id_to_sex_location) as f:\n",
    "    test_datasetid_to_sex = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_to_label = {'M': False, 'F': True}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_name):\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "     \n",
    "    return mfccsscaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.zeros((len(train_datasetid_to_filepath), 41)) # 40 features from the extract_features method + label\n",
    "\n",
    "for i, zip_contents in enumerate(tzip(train_datasetid_to_filepath.items(), train_datasetid_to_sex.items())):\n",
    "    filepath_row, sex_row = zip_contents\n",
    "    _, filepath = filepath_row\n",
    "    _, sex = sex_row\n",
    "    train_features[i, 0:40] = extract_features(filepath)\n",
    "    train_features[i, 40] = float(sex_to_label[sex])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = np.zeros((len(test_datasetid_to_filepath), 41))\n",
    "\n",
    "for i, zip_contents in enumerate(tzip(test_datasetid_to_filepath.items(), test_datasetid_to_sex.items())):\n",
    "    filepath_row, sex_row = zip_contents\n",
    "    _, filepath = filepath_row\n",
    "    _, sex = sex_row\n",
    "    test_features[i, 0:40] = extract_features(filepath)\n",
    "    test_features[i, 40] = float(sex_to_label[sex])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save features for future use\n",
    "np.save(\"train_mfcc.npy\", train_features)\n",
    "np.save(\"test_mfcc.npy\", test_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features incase they are already created to save time\n",
    "train_features = np.load(\"train_mfcc.npy\")\n",
    "test_features = np.load(\"test_mfcc.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LibriSpeechMFCCDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features):\n",
    "        self.n_samples = features.shape[0]\n",
    "        self.X = torch.from_numpy(features[:, :-1].reshape(self.n_samples, 1, 4, 10))\n",
    "        self.y = torch.from_numpy(features[:, -1])\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batchsize = 8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = LibriSpeechMFCCDataset(train_features)\n",
    "testset = LibriSpeechMFCCDataset(test_features)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=batchsize, shuffle=True, drop_last=True)\n",
    "testloader = DataLoader(testset, batch_size=batchsize, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Network Structure and Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "  (output): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, 2, padding=1)\n",
    "        \n",
    "        x = torch.randn(4, 10).view(-1, 1, 4, 10)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "        \n",
    "        self.output = nn.Linear(self._to_linear, 1)\n",
    "        \n",
    "    def convs(self, x):\n",
    "        drop = nn.Dropout(0.2)\n",
    "        # print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        # print(x.shape)\n",
    "        x = F.relu(x)\n",
    "        # print(x.shape)\n",
    "        x = F.max_pool2d(x, (2, 2))\n",
    "        # print(x.shape)\n",
    "        x = drop(x)\n",
    "        # print(\"---\")\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        # print(x.shape)\n",
    "        x = F.relu(x)\n",
    "        # print(x.shape)\n",
    "        x = F.max_pool2d(x, (2, 2))\n",
    "        # print(x.shape)\n",
    "        x = drop(x)\n",
    "        # print(\"---\")\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        # print(x.shape)\n",
    "        x = F.relu(x)\n",
    "        # print(x.shape)\n",
    "        x = F.max_pool2d(x, (2, 2))\n",
    "        # print(x.shape)\n",
    "        x = drop(x)\n",
    "        # print(\"---\")\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        # print(x.shape)\n",
    "        x = F.relu(x)\n",
    "        # print(x.shape)\n",
    "        x = F.max_pool2d(x, (2, 2))\n",
    "        # print(x.shape)\n",
    "        x = drop(x)\n",
    "        # print(\"---\")\n",
    "\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        # print(self._to_linear)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)\n",
    "        x = torch.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment print statements above you get:\n",
    "# torch.Size([1, 1, 4, 10])\n",
    "# torch.Size([1, 16, 5, 11])\n",
    "# torch.Size([1, 16, 5, 11])\n",
    "# torch.Size([1, 16, 2, 5])\n",
    "# ---\n",
    "# torch.Size([1, 32, 3, 6])\n",
    "# torch.Size([1, 32, 3, 6])\n",
    "# torch.Size([1, 32, 1, 3])\n",
    "# ---\n",
    "# torch.Size([1, 64, 2, 4])\n",
    "# torch.Size([1, 64, 2, 4])\n",
    "# torch.Size([1, 64, 1, 2])\n",
    "# ---\n",
    "# torch.Size([1, 128, 2, 3])\n",
    "# torch.Size([1, 128, 2, 3])\n",
    "# torch.Size([1, 128, 1, 1])\n",
    "# 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Hyper-Parameters #\n",
    "####################\n",
    "\n",
    "learning_rate = 0.005\n",
    "momentum = 0.9\n",
    "n_epochs = 5\n",
    "evaluate_every_n_batches = 800\n",
    "\n",
    "criterion = nn.BCELoss() # Binary Cross Entropy\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            batch, labels = data\n",
    "            predicted = model(batch)\n",
    "            total += labels.size(0)\n",
    "            correct += ((predicted > 0.5)[:, 0] == labels.byte()).cpu().sum().numpy()\n",
    "\n",
    "    return correct * 1.0 / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "val_acc_values = []\n",
    "acc_values = []\n",
    "t0 = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    running_correct_samples = 0\n",
    "    for i, data in enumerate(tqdm(trainloader), 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net.forward(inputs.double())\n",
    "        loss = criterion(outputs, labels.reshape((batchsize, 1)).double())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Evaluation and learning rate decay\n",
    "        running_loss += loss.item()\n",
    "        running_correct_samples += torch.eq((outputs[:, 0] > 0.5).cpu(), labels.byte()).numpy().sum()\n",
    "        if i % evaluate_every_n_batches == evaluate_every_n_batches - 1:\n",
    "            val_acc = evaluate(net, testloader)\n",
    "            # return model to training mode\n",
    "            net.train()\n",
    "            print('[%d, %.1f] loss: %.3f acc: %.3f val_acc: %.3f' %\n",
    "                  (epoch + 1, time.time() - t0,\n",
    "                   running_loss / evaluate_every_n_batches,\n",
    "                   running_correct_samples * 1. / (evaluate_every_n_batches * batchsize),\n",
    "                   val_acc))\n",
    "            running_loss = 0.0\n",
    "            running_correct_samples = 0\n",
    "            \n",
    "            val_acc_values.append(val_acc)\n",
    "            acc_values.append((running_correct_samples * 1. / (evaluate_every_n_batches * batchsize)))\n",
    "            \n",
    "            # Save new model if its the best\n",
    "            if val_acc > best_accuracy:\n",
    "                print('Saving new best model.')\n",
    "                torch.save(net.state_dict(), PATH + '/models/' + 'model-' + str(time.time()))\n",
    "                best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8932926829268293"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and evaluate saved model\n",
    "mymodel = Net()\n",
    "mymodel.load_state_dict(torch.load(PATH + \"/models/2d_conv_network/model-1599325173.818381\", map_location=torch.device('cpu')))\n",
    "mymodel.double()\n",
    "evaluate(mymodel, testloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
