{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender Classification with openSLR - 1D CNN\n",
    "This notebook contains my (Hassan Hajarat) attempt in training the \"Open Speech & Language Resources\" dataset using a 1D convolutional neural network as an attempt to produce a gender classifier.<br>\n",
    "Data preprocessing/preparation/model evaluation was procured from: https://github.com/oscarknagg/raw-audio-gender-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"raw-audio-gender-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.py from https://github.com/oscarknagg/raw-audio-gender-classification/blob/master/data.py\n",
    "import torch.utils.data\n",
    "import soundfile as sf\n",
    "\n",
    "sex_to_label = {'M': False, 'F': True}\n",
    "label_to_sex = {False: 'M', True: 'F'}\n",
    "PATH = os.getcwd()\n",
    "\n",
    "\n",
    "class LibriSpeechDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, subsets, length, stochastic=True, cache=True):\n",
    "        \"\"\"\n",
    "        This class subclasses the torch Dataset object. The __getitem__ function will return a raw audio sample and it's\n",
    "        label.\n",
    "        :param subsets: What LibriSpeech datasets to use\n",
    "        :param length: Number of audio samples to take from each file. Any files shorter than this will be ignored.\n",
    "        :param stochastic: If True then we will take a random fragment from each file of sufficient length. If False we\n",
    "        wil always take a fragment starting at the beginning of a file.\n",
    "        \"\"\"\n",
    "        self.subset = subsets\n",
    "        self.fragment_length = length\n",
    "        self.stochastic = stochastic\n",
    "\n",
    "        print('Initialising LibriSpeechDataset with length = {} and subsets = {}'.format(length, subsets))\n",
    "\n",
    "        # Convert subset to list if it is a string\n",
    "        # This allows to handle list of multiple subsets the same a single subset\n",
    "        if isinstance(subsets, str):\n",
    "            subsets = [subsets]\n",
    "\n",
    "        # Check if we have already indexed the files\n",
    "        cached_id_to_filepath_location = '/data/LibriSpeech__datasetid_to_filepath__subsets={}__length={}.json'.format(\n",
    "            subsets, length)\n",
    "        cached_id_to_filepath_location = PATH + cached_id_to_filepath_location\n",
    "\n",
    "        cached_id_to_sex_location = '/data/LibriSpeech__datasetid_to_sex__subsets={}__length={}.json'.format(\n",
    "            subsets, length)\n",
    "        cached_id_to_sex_location = PATH + cached_id_to_sex_location\n",
    "\n",
    "        cached_dictionaries_exist = os.path.exists(cached_id_to_filepath_location) \\\n",
    "            and os.path.exists(cached_id_to_sex_location)\n",
    "        if cache and cached_dictionaries_exist:\n",
    "            print('Cached indexes found.')\n",
    "            with open(cached_id_to_filepath_location) as f:\n",
    "                self.datasetid_to_filepath = json.load(f)\n",
    "\n",
    "            with open(cached_id_to_sex_location) as f:\n",
    "                self.datasetid_to_sex = json.load(f)\n",
    "\n",
    "            # The dictionaries loaded from json have string type keys\n",
    "            # Convert them back to integers\n",
    "            self.datasetid_to_filepath = {int(k): v for k, v in self.datasetid_to_filepath.items()}\n",
    "            self.datasetid_to_sex = {int(k): v for k, v in self.datasetid_to_sex.items()}\n",
    "\n",
    "            assert len(self.datasetid_to_filepath) == len(self.datasetid_to_sex), 'Cached indexes are different lengths!'\n",
    "\n",
    "            self.n_files = len(self.datasetid_to_filepath)\n",
    "            print('{} usable files found.'.format(self.n_files))\n",
    "\n",
    "            return\n",
    "\n",
    "        df = pd.read_csv(PATH+'/data/LibriSpeech/SPEAKERS.TXT', skiprows=11, delimiter='|', error_bad_lines=False)\n",
    "        df.columns = [col.strip().replace(';', '').lower() for col in df.columns]\n",
    "        df = df.assign(\n",
    "            sex=df['sex'].apply(lambda x: x.strip()),\n",
    "            subset=df['subset'].apply(lambda x: x.strip()),\n",
    "            name=df['name'].apply(lambda x: x.strip()),\n",
    "        )\n",
    "\n",
    "        # Get id -> sex mapping\n",
    "        librispeech_id_to_sex = df[df['subset'].isin(subsets)][['id', 'sex']].to_dict()\n",
    "        self.librispeech_id_to_sex = {\n",
    "            k: v for k, v in zip(librispeech_id_to_sex['id'].values(), librispeech_id_to_sex['sex'].values())}\n",
    "        librispeech_id_to_name = df[df['subset'].isin(subsets)][['id', 'name']].to_dict()\n",
    "        self.librispeech_id_to_name = {\n",
    "            k: v for k, v in zip(librispeech_id_to_name['id'].values(), librispeech_id_to_name['name'].values())}\n",
    "\n",
    "        datasetid = 0\n",
    "        self.n_files = 0\n",
    "        self.datasetid_to_filepath = {}\n",
    "        self.datasetid_to_sex = {}\n",
    "        self.datasetid_to_name = {}\n",
    "\n",
    "        for s in subsets:\n",
    "            print('Indexing {}...'.format(s))\n",
    "            # Quick first pass to find total for tqdm bar\n",
    "            subset_len = 0\n",
    "            for root, folders, files in os.walk(PATH+'/data/LibriSpeech/{}/'.format(s)):\n",
    "                subset_len += len([f for f in files if f.endswith('.flac')])\n",
    "\n",
    "            progress_bar = tqdm(total=subset_len)\n",
    "            for root, folders, files in os.walk(PATH+'/data/LibriSpeech/{}/'.format(s)):\n",
    "                if len(files) == 0:\n",
    "                    continue\n",
    "\n",
    "                librispeech_id = int(root.split('/')[-2])\n",
    "\n",
    "                for f in files:\n",
    "                    # Skip non-sound files\n",
    "                    if not f.endswith('.flac'):\n",
    "                        continue\n",
    "\n",
    "                    progress_bar.update(1)\n",
    "\n",
    "                    # Skip short files\n",
    "                    instance, samplerate = sf.read(os.path.join(root, f))\n",
    "                    if len(instance) <= self.fragment_length:\n",
    "                        continue\n",
    "\n",
    "                    self.datasetid_to_filepath[datasetid] = os.path.abspath(os.path.join(root, f))\n",
    "                    self.datasetid_to_sex[datasetid] = self.librispeech_id_to_sex[librispeech_id]\n",
    "                    self.datasetid_to_name[datasetid] = self.librispeech_id_to_name[librispeech_id]\n",
    "                    datasetid += 1\n",
    "                    self.n_files += 1\n",
    "\n",
    "            progress_bar.close()\n",
    "        print('Finished indexing data. {} usable files found.'.format(self.n_files))\n",
    "\n",
    "        # Save relevant dictionaries to json in order to re-use them layer\n",
    "        # The indexing takes a few minutes each time and would be nice to just perform this calculation once\n",
    "        with open(cached_id_to_filepath_location, 'w') as f:\n",
    "            json.dump(self.datasetid_to_filepath, f)\n",
    "\n",
    "        with open(cached_id_to_sex_location, 'w') as f:\n",
    "            json.dump(self.datasetid_to_sex, f)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        instance, samplerate = sf.read(self.datasetid_to_filepath[index])\n",
    "        # Choose a random sample of the file\n",
    "        if self.stochastic:\n",
    "            fragment_start_index = np.random.randint(0, len(instance)-self.fragment_length)\n",
    "        else:\n",
    "            fragment_start_index = 0\n",
    "        instance = instance[fragment_start_index:fragment_start_index+self.fragment_length]\n",
    "        sex = self.datasetid_to_sex[index]\n",
    "        return instance, sex_to_label[sex]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "LIBRISPEECH_SAMPLING_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Hyper-Parameters #\n",
    "####################\n",
    "\n",
    "n_seconds = 3 # We want the first 3 seconds of each recording only\n",
    "downsampling = 4 # 4 times downsampled data (4000 point each seconds instead of 16000)\n",
    "batchsize = 8\n",
    "training_set = ['train-clean-100']\n",
    "validation_set = 'dev-clean'\n",
    "learning_rate = 0.005\n",
    "n_epochs = 7 # More than enough\n",
    "\n",
    "# Extra params\n",
    "momentum = 0.9\n",
    "evaluate_every_n_batches = 800\n",
    "reduce_lr_patience = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising LibriSpeechDataset with length = 48000 and subsets = ['train-clean-100']\n",
      "Cached indexes found.\n",
      "27949 usable files found.\n",
      "Initialising LibriSpeechDataset with length = 48000 and subsets = dev-clean\n",
      "Cached indexes found.\n",
      "2303 usable files found.\n"
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "# Create datasets/ Access cached indexes #\n",
    "##########################################\n",
    "\n",
    "trainset = LibriSpeechDataset(training_set, int(LIBRISPEECH_SAMPLING_RATE * n_seconds))\n",
    "testset = LibriSpeechDataset(validation_set, int(LIBRISPEECH_SAMPLING_RATE * n_seconds), stochastic=False)\n",
    "trainloader = DataLoader(trainset, batch_size=batchsize, shuffle=True, drop_last=True)\n",
    "testloader = DataLoader(testset, batch_size=batchsize, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (finalconv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (output): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 64, 3, dilation=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 64, 3, dilation=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(64, 64, 3, dilation=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(64, 64, 3, dilation=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.conv5 = nn.Conv1d(64, 64, 3, dilation=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.finalconv = nn.Conv1d(64, 64, 3, dilation=1, padding=1)\n",
    "        \n",
    "        self.output = nn.Linear(64, 1) # True or false value\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.max_pool1d(self.bn2(F.relu(self.conv2(x))), kernel_size=3, stride=3)\n",
    "        x = F.max_pool1d(self.bn3(F.relu(self.conv3(x))), kernel_size=3, stride=3)\n",
    "        x = F.max_pool1d(self.bn4(F.relu(self.conv4(x))), kernel_size=3, stride=3)\n",
    "        x = F.max_pool1d(self.bn5(F.relu(self.conv5(x))), kernel_size=3, stride=3)\n",
    "        x = F.max_pool1d(F.relu(self.finalconv(x)), kernel_size=x.size()[2:])\n",
    "        x = x.view(-1, 64)\n",
    "        x = torch.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# Define loss and optimiser #\n",
    "#############################\n",
    "import torch.optim as optim\n",
    "criterion = nn.BCELoss() # Binary Cross Entropy\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "# This scheduler reduces lr on command\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=reduce_lr_patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import whiten, evaluate\n",
    "from scipy.signal import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing method for each batch when needed\n",
    "def preprocessor(batch):\n",
    "    batch = whiten(batch)\n",
    "    batch = torch.from_numpy(\n",
    "        resample(batch, int(LIBRISPEECH_SAMPLING_RATE * n_seconds / downsampling), axis=1)\n",
    "    ).reshape((batchsize, 1, int(LIBRISPEECH_SAMPLING_RATE * n_seconds / downsampling)))\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "val_acc_values = []\n",
    "acc_values = []\n",
    "t0 = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    running_correct_samples = 0\n",
    "    for i, data in enumerate(tqdm(trainloader, position=0), 0):\n",
    "        inputs, labels = data\n",
    "        # Normalise the volume to a fixed root mean square value as some speakers are much quieter than others\n",
    "        inputs = whiten(inputs)\n",
    "        # Resample audio\n",
    "        inputs = torch.from_numpy(\n",
    "            resample(inputs, int(LIBRISPEECH_SAMPLING_RATE * n_seconds / downsampling), axis=1)\n",
    "        ).reshape((batchsize, 1, int(LIBRISPEECH_SAMPLING_RATE * n_seconds / downsampling))).double()\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward + backward + optimize\n",
    "        outputs = net.forward(inputs)\n",
    "        loss = criterion(outputs, labels.reshape((batchsize, 1)).double())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Evaluation and learning rate decay\n",
    "        running_loss += loss.item()\n",
    "        running_correct_samples += torch.eq((outputs[:, 0] > 0.5).cpu(), labels.byte()).numpy().sum()\n",
    "        if i % evaluate_every_n_batches == evaluate_every_n_batches - 1:\n",
    "            val_acc = evaluate(net, testloader, preprocessor)\n",
    "            # return model to training mode\n",
    "            net.train()\n",
    "            print('[%d, %.1f] loss: %.3f acc: %.3f val_acc: %.3f' %\n",
    "                  (epoch + 1, time.time() - t0,\n",
    "                   running_loss / evaluate_every_n_batches,\n",
    "                   running_correct_samples * 1. / (evaluate_every_n_batches * batchsize),\n",
    "                   val_acc))\n",
    "            running_loss = 0.0\n",
    "            running_correct_samples = 0\n",
    "            \n",
    "            val_acc_values.append(val_acc)\n",
    "            acc_values.append((running_correct_samples * 1. / (evaluate_every_n_batches * batchsize)))\n",
    "            \n",
    "            # Save new model if its the best\n",
    "            if val_acc > best_accuracy:\n",
    "                print('Saving new best model.')\n",
    "                torch.save(net.state_dict(), PATH + '/models/' + 'model-' + str(time.time()))\n",
    "                best_accuracy = val_acc\n",
    "            \n",
    "            # Check for plateau (reduce lr if so)\n",
    "            scheduler.step(val_acc)\n",
    "            \n",
    "    \n",
    "print('\\nFinished Training')\n",
    "print('Best validation accuracy was {:.3f}'.format(best_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(net.state_dict(), PATH + '/models/' + 'model-' + str(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/287 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/287 [00:00<02:19,  2.05it/s]\u001b[A\n",
      "  1%|          | 2/287 [00:00<02:11,  2.16it/s]\u001b[A\n",
      "  1%|          | 3/287 [00:01<02:08,  2.22it/s]\u001b[A\n",
      "  1%|▏         | 4/287 [00:01<02:15,  2.09it/s]\u001b[A\n",
      "  2%|▏         | 5/287 [00:02<02:22,  1.97it/s]\u001b[A\n",
      "  2%|▏         | 6/287 [00:02<02:14,  2.09it/s]\u001b[A\n",
      "  2%|▏         | 7/287 [00:03<02:08,  2.19it/s]\u001b[A\n",
      "  3%|▎         | 8/287 [00:03<02:03,  2.26it/s]\u001b[A\n",
      "  3%|▎         | 9/287 [00:04<02:02,  2.27it/s]\u001b[A\n",
      "  3%|▎         | 10/287 [00:04<02:00,  2.29it/s]\u001b[A\n",
      "  4%|▍         | 11/287 [00:04<01:58,  2.32it/s]\u001b[A\n",
      "  4%|▍         | 12/287 [00:05<01:56,  2.36it/s]\u001b[A\n",
      "  5%|▍         | 13/287 [00:05<01:53,  2.42it/s]\u001b[A\n",
      "  5%|▍         | 14/287 [00:06<01:52,  2.42it/s]\u001b[A\n",
      "  5%|▌         | 15/287 [00:06<01:51,  2.43it/s]\u001b[A\n",
      "  6%|▌         | 16/287 [00:07<01:59,  2.26it/s]\u001b[A\n",
      "  6%|▌         | 17/287 [00:07<02:07,  2.12it/s]\u001b[A\n",
      "  6%|▋         | 18/287 [00:08<02:03,  2.17it/s]\u001b[A\n",
      "  7%|▋         | 19/287 [00:08<01:59,  2.24it/s]\u001b[A\n",
      "  7%|▋         | 20/287 [00:08<01:56,  2.30it/s]\u001b[A\n",
      "  7%|▋         | 21/287 [00:09<01:53,  2.34it/s]\u001b[A\n",
      "  8%|▊         | 22/287 [00:09<01:51,  2.37it/s]\u001b[A\n",
      "  8%|▊         | 23/287 [00:10<01:49,  2.41it/s]\u001b[A\n",
      "  8%|▊         | 24/287 [00:10<01:47,  2.44it/s]\u001b[A\n",
      "  9%|▊         | 25/287 [00:10<01:47,  2.44it/s]\u001b[A\n",
      "  9%|▉         | 26/287 [00:11<01:46,  2.45it/s]\u001b[A\n",
      "  9%|▉         | 27/287 [00:11<01:47,  2.43it/s]\u001b[A\n",
      " 10%|▉         | 28/287 [00:12<01:47,  2.42it/s]\u001b[A\n",
      " 10%|█         | 29/287 [00:12<01:46,  2.43it/s]\u001b[A\n",
      " 10%|█         | 30/287 [00:13<01:55,  2.22it/s]\u001b[A\n",
      " 11%|█         | 31/287 [00:13<02:02,  2.09it/s]\u001b[A\n",
      " 11%|█         | 32/287 [00:14<02:03,  2.07it/s]\u001b[A\n",
      " 11%|█▏        | 33/287 [00:14<02:02,  2.08it/s]\u001b[A\n",
      " 12%|█▏        | 34/287 [00:14<01:54,  2.21it/s]\u001b[A\n",
      " 12%|█▏        | 35/287 [00:15<01:52,  2.24it/s]\u001b[A\n",
      " 13%|█▎        | 36/287 [00:15<01:49,  2.29it/s]\u001b[A\n",
      " 13%|█▎        | 37/287 [00:16<01:47,  2.32it/s]\u001b[A\n",
      " 13%|█▎        | 38/287 [00:16<01:48,  2.30it/s]\u001b[A\n",
      " 14%|█▎        | 39/287 [00:17<01:46,  2.34it/s]\u001b[A\n",
      " 14%|█▍        | 40/287 [00:17<01:45,  2.33it/s]\u001b[A\n",
      " 14%|█▍        | 41/287 [00:17<01:42,  2.40it/s]\u001b[A\n",
      " 15%|█▍        | 42/287 [00:18<01:42,  2.40it/s]\u001b[A\n",
      " 15%|█▍        | 43/287 [00:18<01:39,  2.45it/s]\u001b[A\n",
      " 15%|█▌        | 44/287 [00:19<01:39,  2.45it/s]\u001b[A\n",
      " 16%|█▌        | 45/287 [00:19<01:39,  2.43it/s]\u001b[A\n",
      " 16%|█▌        | 46/287 [00:19<01:39,  2.43it/s]\u001b[A\n",
      " 16%|█▋        | 47/287 [00:20<01:39,  2.42it/s]\u001b[A\n",
      " 17%|█▋        | 48/287 [00:20<01:37,  2.45it/s]\u001b[A\n",
      " 17%|█▋        | 49/287 [00:21<01:37,  2.45it/s]\u001b[A\n",
      " 17%|█▋        | 50/287 [00:21<01:36,  2.46it/s]\u001b[A\n",
      " 18%|█▊        | 51/287 [00:22<01:36,  2.44it/s]\u001b[A\n",
      " 18%|█▊        | 52/287 [00:22<01:36,  2.43it/s]\u001b[A\n",
      " 18%|█▊        | 53/287 [00:22<01:36,  2.42it/s]\u001b[A\n",
      " 19%|█▉        | 54/287 [00:23<01:35,  2.43it/s]\u001b[A\n",
      " 19%|█▉        | 55/287 [00:23<01:34,  2.45it/s]\u001b[A\n",
      " 20%|█▉        | 56/287 [00:24<01:33,  2.46it/s]\u001b[A\n",
      " 20%|█▉        | 57/287 [00:24<01:33,  2.46it/s]\u001b[A\n",
      " 20%|██        | 58/287 [00:24<01:33,  2.46it/s]\u001b[A\n",
      " 21%|██        | 59/287 [00:25<01:32,  2.46it/s]\u001b[A\n",
      " 21%|██        | 60/287 [00:25<01:32,  2.46it/s]\u001b[A\n",
      " 21%|██▏       | 61/287 [00:26<01:31,  2.46it/s]\u001b[A\n",
      " 22%|██▏       | 62/287 [00:26<01:31,  2.47it/s]\u001b[A\n",
      " 22%|██▏       | 63/287 [00:26<01:30,  2.48it/s]\u001b[A\n",
      " 22%|██▏       | 64/287 [00:27<01:30,  2.45it/s]\u001b[A\n",
      " 23%|██▎       | 65/287 [00:27<01:30,  2.46it/s]\u001b[A\n",
      " 23%|██▎       | 66/287 [00:28<01:29,  2.47it/s]\u001b[A\n",
      " 23%|██▎       | 67/287 [00:28<01:29,  2.47it/s]\u001b[A\n",
      " 24%|██▎       | 68/287 [00:28<01:28,  2.47it/s]\u001b[A\n",
      " 24%|██▍       | 69/287 [00:29<01:27,  2.49it/s]\u001b[A\n",
      " 24%|██▍       | 70/287 [00:29<01:27,  2.48it/s]\u001b[A\n",
      " 25%|██▍       | 71/287 [00:30<01:27,  2.47it/s]\u001b[A\n",
      " 25%|██▌       | 72/287 [00:30<01:27,  2.46it/s]\u001b[A\n",
      " 25%|██▌       | 73/287 [00:30<01:28,  2.43it/s]\u001b[A\n",
      " 26%|██▌       | 74/287 [00:31<01:27,  2.42it/s]\u001b[A\n",
      " 26%|██▌       | 75/287 [00:31<01:27,  2.42it/s]\u001b[A\n",
      " 26%|██▋       | 76/287 [00:32<01:27,  2.42it/s]\u001b[A\n",
      " 27%|██▋       | 77/287 [00:32<01:27,  2.41it/s]\u001b[A\n",
      " 27%|██▋       | 78/287 [00:33<01:26,  2.41it/s]\u001b[A\n",
      " 28%|██▊       | 79/287 [00:33<01:27,  2.38it/s]\u001b[A\n",
      " 28%|██▊       | 80/287 [00:33<01:27,  2.37it/s]\u001b[A\n",
      " 28%|██▊       | 81/287 [00:34<01:26,  2.37it/s]\u001b[A\n",
      " 29%|██▊       | 82/287 [00:34<01:26,  2.37it/s]\u001b[A\n",
      " 29%|██▉       | 83/287 [00:35<01:26,  2.36it/s]\u001b[A\n",
      " 29%|██▉       | 84/287 [00:35<01:25,  2.39it/s]\u001b[A\n",
      " 30%|██▉       | 85/287 [00:36<01:25,  2.37it/s]\u001b[A\n",
      " 30%|██▉       | 86/287 [00:36<01:24,  2.37it/s]\u001b[A\n",
      " 30%|███       | 87/287 [00:36<01:29,  2.25it/s]\u001b[A\n",
      " 31%|███       | 88/287 [00:37<01:27,  2.28it/s]\u001b[A\n",
      " 31%|███       | 89/287 [00:37<01:24,  2.34it/s]\u001b[A\n",
      " 31%|███▏      | 90/287 [00:38<01:23,  2.36it/s]\u001b[A\n",
      " 32%|███▏      | 91/287 [00:38<01:24,  2.33it/s]\u001b[A\n",
      " 32%|███▏      | 92/287 [00:39<01:24,  2.31it/s]\u001b[A\n",
      " 32%|███▏      | 93/287 [00:39<01:23,  2.33it/s]\u001b[A\n",
      " 33%|███▎      | 94/287 [00:39<01:24,  2.29it/s]\u001b[A\n",
      " 33%|███▎      | 95/287 [00:40<01:23,  2.29it/s]\u001b[A\n",
      " 33%|███▎      | 96/287 [00:40<01:22,  2.30it/s]\u001b[A\n",
      " 34%|███▍      | 97/287 [00:41<01:21,  2.32it/s]\u001b[A\n",
      " 34%|███▍      | 98/287 [00:41<01:20,  2.35it/s]\u001b[A\n",
      " 34%|███▍      | 99/287 [00:42<01:20,  2.33it/s]\u001b[A\n",
      " 35%|███▍      | 100/287 [00:42<01:19,  2.34it/s]\u001b[A\n",
      " 35%|███▌      | 101/287 [00:42<01:19,  2.35it/s]\u001b[A\n",
      " 36%|███▌      | 102/287 [00:43<01:19,  2.32it/s]\u001b[A\n",
      " 36%|███▌      | 103/287 [00:43<01:19,  2.30it/s]\u001b[A\n",
      " 36%|███▌      | 104/287 [00:44<01:19,  2.31it/s]\u001b[A\n",
      " 37%|███▋      | 105/287 [00:44<01:19,  2.28it/s]\u001b[A\n",
      " 37%|███▋      | 106/287 [00:45<01:18,  2.31it/s]\u001b[A\n",
      " 37%|███▋      | 107/287 [00:45<01:17,  2.32it/s]\u001b[A\n",
      " 38%|███▊      | 108/287 [00:45<01:17,  2.31it/s]\u001b[A\n",
      " 38%|███▊      | 109/287 [00:46<01:16,  2.34it/s]\u001b[A\n",
      " 38%|███▊      | 110/287 [00:46<01:15,  2.33it/s]\u001b[A\n",
      " 39%|███▊      | 111/287 [00:47<01:14,  2.36it/s]\u001b[A\n",
      " 39%|███▉      | 112/287 [00:47<01:14,  2.36it/s]\u001b[A\n",
      " 39%|███▉      | 113/287 [00:48<01:14,  2.35it/s]\u001b[A\n",
      " 40%|███▉      | 114/287 [00:48<01:13,  2.35it/s]\u001b[A\n",
      " 40%|████      | 115/287 [00:48<01:13,  2.34it/s]\u001b[A\n",
      " 40%|████      | 116/287 [00:49<01:13,  2.33it/s]\u001b[A\n",
      " 41%|████      | 117/287 [00:49<01:13,  2.31it/s]\u001b[A\n",
      " 41%|████      | 118/287 [00:50<01:18,  2.15it/s]\u001b[A\n",
      " 41%|████▏     | 119/287 [00:50<01:16,  2.19it/s]\u001b[A\n",
      " 42%|████▏     | 120/287 [00:51<01:15,  2.20it/s]\u001b[A\n",
      " 42%|████▏     | 121/287 [00:51<01:14,  2.24it/s]\u001b[A\n",
      " 43%|████▎     | 122/287 [00:52<01:12,  2.28it/s]\u001b[A\n",
      " 43%|████▎     | 123/287 [00:52<01:10,  2.32it/s]\u001b[A\n",
      " 43%|████▎     | 124/287 [00:52<01:09,  2.34it/s]\u001b[A\n",
      " 44%|████▎     | 125/287 [00:53<01:10,  2.31it/s]\u001b[A\n",
      " 44%|████▍     | 126/287 [00:53<01:09,  2.33it/s]\u001b[A\n",
      " 44%|████▍     | 127/287 [00:54<01:08,  2.35it/s]\u001b[A\n",
      " 45%|████▍     | 128/287 [00:54<01:08,  2.32it/s]\u001b[A\n",
      " 45%|████▍     | 129/287 [00:55<01:07,  2.35it/s]\u001b[A\n",
      " 45%|████▌     | 130/287 [00:55<01:07,  2.33it/s]\u001b[A\n",
      " 46%|████▌     | 131/287 [00:55<01:07,  2.30it/s]\u001b[A\n",
      " 46%|████▌     | 132/287 [00:56<01:06,  2.31it/s]\u001b[A\n",
      " 46%|████▋     | 133/287 [00:56<01:05,  2.35it/s]\u001b[A\n",
      " 47%|████▋     | 134/287 [00:57<01:05,  2.33it/s]\u001b[A\n",
      " 47%|████▋     | 135/287 [00:57<01:04,  2.35it/s]\u001b[A\n",
      " 47%|████▋     | 136/287 [00:58<01:04,  2.35it/s]\u001b[A\n",
      " 48%|████▊     | 137/287 [00:58<01:04,  2.34it/s]\u001b[A\n",
      " 48%|████▊     | 138/287 [00:58<01:03,  2.35it/s]\u001b[A\n",
      " 48%|████▊     | 139/287 [00:59<01:02,  2.36it/s]\u001b[A\n",
      " 49%|████▉     | 140/287 [00:59<01:02,  2.34it/s]\u001b[A\n",
      " 49%|████▉     | 141/287 [01:00<01:02,  2.33it/s]\u001b[A\n",
      " 49%|████▉     | 142/287 [01:00<01:02,  2.34it/s]\u001b[A\n",
      " 50%|████▉     | 143/287 [01:01<01:02,  2.32it/s]\u001b[A\n",
      " 50%|█████     | 144/287 [01:01<01:01,  2.31it/s]\u001b[A\n",
      " 51%|█████     | 145/287 [01:01<01:01,  2.33it/s]\u001b[A\n",
      " 51%|█████     | 146/287 [01:02<01:01,  2.30it/s]\u001b[A\n",
      " 51%|█████     | 147/287 [01:02<01:00,  2.32it/s]\u001b[A\n",
      " 52%|█████▏    | 148/287 [01:03<00:59,  2.35it/s]\u001b[A\n",
      " 52%|█████▏    | 149/287 [01:03<00:58,  2.34it/s]\u001b[A\n",
      " 52%|█████▏    | 150/287 [01:04<00:58,  2.34it/s]\u001b[A\n",
      " 53%|█████▎    | 151/287 [01:04<00:57,  2.35it/s]\u001b[A\n",
      " 53%|█████▎    | 152/287 [01:04<00:58,  2.31it/s]\u001b[A\n",
      " 53%|█████▎    | 153/287 [01:05<00:57,  2.32it/s]\u001b[A\n",
      " 54%|█████▎    | 154/287 [01:05<00:57,  2.30it/s]\u001b[A\n",
      " 54%|█████▍    | 155/287 [01:06<00:57,  2.29it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 156/287 [01:06<00:56,  2.32it/s]\u001b[A\n",
      " 55%|█████▍    | 157/287 [01:07<00:57,  2.28it/s]\u001b[A\n",
      " 55%|█████▌    | 158/287 [01:07<00:55,  2.33it/s]\u001b[A\n",
      " 55%|█████▌    | 159/287 [01:07<00:54,  2.36it/s]\u001b[A\n",
      " 56%|█████▌    | 160/287 [01:08<00:53,  2.39it/s]\u001b[A\n",
      " 56%|█████▌    | 161/287 [01:08<00:52,  2.40it/s]\u001b[A\n",
      " 56%|█████▋    | 162/287 [01:09<00:51,  2.43it/s]\u001b[A\n",
      " 57%|█████▋    | 163/287 [01:09<00:51,  2.42it/s]\u001b[A\n",
      " 57%|█████▋    | 164/287 [01:09<00:50,  2.41it/s]\u001b[A\n",
      " 57%|█████▋    | 165/287 [01:10<00:50,  2.39it/s]\u001b[A\n",
      " 58%|█████▊    | 166/287 [01:10<00:50,  2.39it/s]\u001b[A\n",
      " 58%|█████▊    | 167/287 [01:11<00:50,  2.38it/s]\u001b[A\n",
      " 59%|█████▊    | 168/287 [01:11<00:49,  2.40it/s]\u001b[A\n",
      " 59%|█████▉    | 169/287 [01:12<00:49,  2.40it/s]\u001b[A\n",
      " 59%|█████▉    | 170/287 [01:12<00:48,  2.41it/s]\u001b[A\n",
      " 60%|█████▉    | 171/287 [01:12<00:48,  2.42it/s]\u001b[A\n",
      " 60%|█████▉    | 172/287 [01:13<00:47,  2.41it/s]\u001b[A\n",
      " 60%|██████    | 173/287 [01:13<00:47,  2.39it/s]\u001b[A\n",
      " 61%|██████    | 174/287 [01:14<00:47,  2.39it/s]\u001b[A\n",
      " 61%|██████    | 175/287 [01:14<00:46,  2.39it/s]\u001b[A\n",
      " 61%|██████▏   | 176/287 [01:15<00:46,  2.38it/s]\u001b[A\n",
      " 62%|██████▏   | 177/287 [01:15<00:45,  2.40it/s]\u001b[A\n",
      " 62%|██████▏   | 178/287 [01:15<00:45,  2.40it/s]\u001b[A\n",
      " 62%|██████▏   | 179/287 [01:16<00:44,  2.42it/s]\u001b[A\n",
      " 63%|██████▎   | 180/287 [01:16<00:43,  2.43it/s]\u001b[A\n",
      " 63%|██████▎   | 181/287 [01:17<00:43,  2.44it/s]\u001b[A\n",
      " 63%|██████▎   | 182/287 [01:17<00:43,  2.41it/s]\u001b[A\n",
      " 64%|██████▍   | 183/287 [01:17<00:43,  2.41it/s]\u001b[A\n",
      " 64%|██████▍   | 184/287 [01:18<00:42,  2.43it/s]\u001b[A\n",
      " 64%|██████▍   | 185/287 [01:18<00:41,  2.47it/s]\u001b[A\n",
      " 65%|██████▍   | 186/287 [01:19<00:40,  2.50it/s]\u001b[A\n",
      " 65%|██████▌   | 187/287 [01:19<00:40,  2.47it/s]\u001b[A\n",
      " 66%|██████▌   | 188/287 [01:19<00:39,  2.48it/s]\u001b[A\n",
      " 66%|██████▌   | 189/287 [01:20<00:39,  2.50it/s]\u001b[A\n",
      " 66%|██████▌   | 190/287 [01:20<00:38,  2.51it/s]\u001b[A\n",
      " 67%|██████▋   | 191/287 [01:21<00:38,  2.52it/s]\u001b[A\n",
      " 67%|██████▋   | 192/287 [01:21<00:38,  2.46it/s]\u001b[A\n",
      " 67%|██████▋   | 193/287 [01:21<00:38,  2.43it/s]\u001b[A\n",
      " 68%|██████▊   | 194/287 [01:22<00:38,  2.42it/s]\u001b[A\n",
      " 68%|██████▊   | 195/287 [01:22<00:37,  2.43it/s]\u001b[A\n",
      " 68%|██████▊   | 196/287 [01:23<00:37,  2.41it/s]\u001b[A\n",
      " 69%|██████▊   | 197/287 [01:23<00:37,  2.41it/s]\u001b[A\n",
      " 69%|██████▉   | 198/287 [01:23<00:36,  2.44it/s]\u001b[A\n",
      " 69%|██████▉   | 199/287 [01:24<00:35,  2.48it/s]\u001b[A\n",
      " 70%|██████▉   | 200/287 [01:24<00:34,  2.49it/s]\u001b[A\n",
      " 70%|███████   | 201/287 [01:25<00:34,  2.49it/s]\u001b[A\n",
      " 70%|███████   | 202/287 [01:25<00:33,  2.51it/s]\u001b[A\n",
      " 71%|███████   | 203/287 [01:26<00:36,  2.33it/s]\u001b[A\n",
      " 71%|███████   | 204/287 [01:26<00:35,  2.36it/s]\u001b[A\n",
      " 71%|███████▏  | 205/287 [01:26<00:34,  2.38it/s]\u001b[A\n",
      " 72%|███████▏  | 206/287 [01:27<00:33,  2.41it/s]\u001b[A\n",
      " 72%|███████▏  | 207/287 [01:27<00:33,  2.42it/s]\u001b[A\n",
      " 72%|███████▏  | 208/287 [01:28<00:32,  2.44it/s]\u001b[A\n",
      " 73%|███████▎  | 209/287 [01:28<00:31,  2.46it/s]\u001b[A\n",
      " 73%|███████▎  | 210/287 [01:28<00:31,  2.45it/s]\u001b[A\n",
      " 74%|███████▎  | 211/287 [01:29<00:30,  2.46it/s]\u001b[A\n",
      " 74%|███████▍  | 212/287 [01:29<00:30,  2.47it/s]\u001b[A\n",
      " 74%|███████▍  | 213/287 [01:30<00:29,  2.48it/s]\u001b[A\n",
      " 75%|███████▍  | 214/287 [01:30<00:29,  2.48it/s]\u001b[A\n",
      " 75%|███████▍  | 215/287 [01:30<00:28,  2.49it/s]\u001b[A\n",
      " 75%|███████▌  | 216/287 [01:31<00:28,  2.48it/s]\u001b[A\n",
      " 76%|███████▌  | 217/287 [01:31<00:28,  2.49it/s]\u001b[A\n",
      " 76%|███████▌  | 218/287 [01:32<00:27,  2.47it/s]\u001b[A\n",
      " 76%|███████▋  | 219/287 [01:32<00:27,  2.45it/s]\u001b[A\n",
      " 77%|███████▋  | 220/287 [01:32<00:27,  2.45it/s]\u001b[A\n",
      " 77%|███████▋  | 221/287 [01:33<00:26,  2.48it/s]\u001b[A\n",
      " 77%|███████▋  | 222/287 [01:33<00:26,  2.46it/s]\u001b[A\n",
      " 78%|███████▊  | 223/287 [01:34<00:25,  2.50it/s]\u001b[A\n",
      " 78%|███████▊  | 224/287 [01:34<00:25,  2.51it/s]\u001b[A\n",
      " 78%|███████▊  | 225/287 [01:34<00:24,  2.53it/s]\u001b[A\n",
      " 79%|███████▊  | 226/287 [01:35<00:24,  2.49it/s]\u001b[A\n",
      " 79%|███████▉  | 227/287 [01:35<00:23,  2.51it/s]\u001b[A\n",
      " 79%|███████▉  | 228/287 [01:36<00:23,  2.50it/s]\u001b[A\n",
      " 80%|███████▉  | 229/287 [01:36<00:23,  2.45it/s]\u001b[A\n",
      " 80%|████████  | 230/287 [01:37<00:24,  2.34it/s]\u001b[A\n",
      " 80%|████████  | 231/287 [01:37<00:24,  2.27it/s]\u001b[A\n",
      " 81%|████████  | 232/287 [01:38<00:25,  2.17it/s]\u001b[A\n",
      " 81%|████████  | 233/287 [01:38<00:25,  2.13it/s]\u001b[A\n",
      " 82%|████████▏ | 234/287 [01:38<00:24,  2.17it/s]\u001b[A\n",
      " 82%|████████▏ | 235/287 [01:39<00:23,  2.24it/s]\u001b[A\n",
      " 82%|████████▏ | 236/287 [01:39<00:22,  2.31it/s]\u001b[A\n",
      " 83%|████████▎ | 237/287 [01:40<00:22,  2.26it/s]\u001b[A\n",
      " 83%|████████▎ | 238/287 [01:40<00:21,  2.23it/s]\u001b[A\n",
      " 83%|████████▎ | 239/287 [01:41<00:21,  2.21it/s]\u001b[A\n",
      " 84%|████████▎ | 240/287 [01:41<00:21,  2.20it/s]\u001b[A\n",
      " 84%|████████▍ | 241/287 [01:42<00:21,  2.15it/s]\u001b[A\n",
      " 84%|████████▍ | 242/287 [01:42<00:21,  2.12it/s]\u001b[A\n",
      " 85%|████████▍ | 243/287 [01:43<00:20,  2.12it/s]\u001b[A\n",
      " 85%|████████▌ | 244/287 [01:43<00:20,  2.12it/s]\u001b[A\n",
      " 85%|████████▌ | 245/287 [01:43<00:19,  2.19it/s]\u001b[A\n",
      " 86%|████████▌ | 246/287 [01:44<00:18,  2.28it/s]\u001b[A\n",
      " 86%|████████▌ | 247/287 [01:44<00:17,  2.32it/s]\u001b[A\n",
      " 86%|████████▋ | 248/287 [01:45<00:16,  2.35it/s]\u001b[A\n",
      " 87%|████████▋ | 249/287 [01:45<00:15,  2.40it/s]\u001b[A\n",
      " 87%|████████▋ | 250/287 [01:45<00:15,  2.39it/s]\u001b[A\n",
      " 87%|████████▋ | 251/287 [01:46<00:15,  2.39it/s]\u001b[A\n",
      " 88%|████████▊ | 252/287 [01:46<00:14,  2.44it/s]\u001b[A\n",
      " 88%|████████▊ | 253/287 [01:47<00:13,  2.43it/s]\u001b[A\n",
      " 89%|████████▊ | 254/287 [01:47<00:13,  2.43it/s]\u001b[A\n",
      " 89%|████████▉ | 255/287 [01:48<00:13,  2.41it/s]\u001b[A\n",
      " 89%|████████▉ | 256/287 [01:48<00:12,  2.42it/s]\u001b[A\n",
      " 90%|████████▉ | 257/287 [01:48<00:12,  2.43it/s]\u001b[A\n",
      " 90%|████████▉ | 258/287 [01:49<00:11,  2.45it/s]\u001b[A\n",
      " 90%|█████████ | 259/287 [01:49<00:11,  2.46it/s]\u001b[A\n",
      " 91%|█████████ | 260/287 [01:50<00:11,  2.45it/s]\u001b[A\n",
      " 91%|█████████ | 261/287 [01:50<00:10,  2.46it/s]\u001b[A\n",
      " 91%|█████████▏| 262/287 [01:50<00:10,  2.49it/s]\u001b[A\n",
      " 92%|█████████▏| 263/287 [01:51<00:09,  2.52it/s]\u001b[A\n",
      " 92%|█████████▏| 264/287 [01:51<00:09,  2.54it/s]\u001b[A\n",
      " 92%|█████████▏| 265/287 [01:52<00:08,  2.49it/s]\u001b[A\n",
      " 93%|█████████▎| 266/287 [01:52<00:08,  2.47it/s]\u001b[A\n",
      " 93%|█████████▎| 267/287 [01:52<00:08,  2.40it/s]\u001b[A\n",
      " 93%|█████████▎| 268/287 [01:53<00:08,  2.25it/s]\u001b[A\n",
      " 94%|█████████▎| 269/287 [01:53<00:08,  2.19it/s]\u001b[A\n",
      " 94%|█████████▍| 270/287 [01:54<00:07,  2.17it/s]\u001b[A\n",
      " 94%|█████████▍| 271/287 [01:54<00:07,  2.27it/s]\u001b[A\n",
      " 95%|█████████▍| 272/287 [01:55<00:06,  2.27it/s]\u001b[A\n",
      " 95%|█████████▌| 273/287 [01:55<00:06,  2.29it/s]\u001b[A\n",
      " 95%|█████████▌| 274/287 [01:56<00:05,  2.32it/s]\u001b[A\n",
      " 96%|█████████▌| 275/287 [01:56<00:05,  2.37it/s]\u001b[A\n",
      " 96%|█████████▌| 276/287 [01:56<00:04,  2.42it/s]\u001b[A\n",
      " 97%|█████████▋| 277/287 [01:57<00:04,  2.42it/s]\u001b[A\n",
      " 97%|█████████▋| 278/287 [01:57<00:03,  2.38it/s]\u001b[A\n",
      " 97%|█████████▋| 279/287 [01:58<00:03,  2.39it/s]\u001b[A\n",
      " 98%|█████████▊| 280/287 [01:58<00:02,  2.39it/s]\u001b[A\n",
      " 98%|█████████▊| 281/287 [01:58<00:02,  2.40it/s]\u001b[A\n",
      " 98%|█████████▊| 282/287 [01:59<00:02,  2.43it/s]\u001b[A\n",
      " 99%|█████████▊| 283/287 [01:59<00:01,  2.44it/s]\u001b[A\n",
      " 99%|█████████▉| 284/287 [02:00<00:01,  2.45it/s]\u001b[A\n",
      " 99%|█████████▉| 285/287 [02:00<00:00,  2.47it/s]\u001b[A\n",
      "100%|█████████▉| 286/287 [02:00<00:00,  2.48it/s]\u001b[A\n",
      "100%|██████████| 287/287 [02:01<00:00,  2.36it/s]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9786585365853658"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate my good model\n",
    "downsampling = 4\n",
    "\n",
    "mymodel = Net()\n",
    "mymodel.load_state_dict(torch.load(\"models/Second_conv_network/model-1599233399.234077\", map_location=torch.device('cpu')))\n",
    "mymodel.double()\n",
    "evaluate(mymodel, testloader, preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old unsuccesful network (messed up with the kernel size for the convolutions)\n",
    "class FirstNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 64, 3, dilation=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 64, 3, dilation=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(64, 64, 3, dilation=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(64, 64, 3, dilation=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.conv5 = nn.Conv1d(64, 64, 3, dilation=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.output = nn.Linear(64, 1) # True or false value\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.max_pool1d(self.bn2(F.relu(self.conv2(x))), kernel_size=x.size()[2:]) # kernel_size is 1 here\n",
    "        x = F.max_pool1d(self.bn3(F.relu(self.conv3(x))), kernel_size=x.size()[2:]) # kernel_size is 1 here\n",
    "        x = F.max_pool1d(self.bn4(F.relu(self.conv4(x))), kernel_size=x.size()[2:]) # kernel_size is 1 here\n",
    "        x = F.max_pool1d(self.bn5(F.relu(self.conv5(x))), kernel_size=x.size()[2:])\n",
    "        x = x.view(-1, 64)\n",
    "        x = torch.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "downsampling = 1\n",
    "myoldmodel = FirstNet()\n",
    "myoldmodel.load_state_dict(torch.load(\"models/First_conv_network/model-1599203156.34351\", map_location=torch.device('cpu')))\n",
    "myoldmodel.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/287 [00:00<?, ?it/s]\u001b[A/Users/hajarat/Developer/Workspaces/Github/Mawdoo3AiTask/mawdoo3v/lib/python3.8/site-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "\n",
      "  0%|          | 1/287 [00:01<09:09,  1.92s/it]\u001b[A\n",
      "  1%|          | 2/287 [00:03<08:46,  1.85s/it]\u001b[A\n",
      "  1%|          | 3/287 [00:05<08:30,  1.80s/it]\u001b[A\n",
      "  1%|▏         | 4/287 [00:06<08:18,  1.76s/it]\u001b[A\n",
      "  2%|▏         | 5/287 [00:08<08:09,  1.73s/it]\u001b[A\n",
      "  2%|▏         | 6/287 [00:10<08:04,  1.72s/it]\u001b[A\n",
      "  2%|▏         | 7/287 [00:11<07:56,  1.70s/it]\u001b[A\n",
      "  3%|▎         | 8/287 [00:13<07:52,  1.69s/it]\u001b[A\n",
      "  3%|▎         | 9/287 [00:15<07:49,  1.69s/it]\u001b[A\n",
      "  3%|▎         | 10/287 [00:16<07:45,  1.68s/it]\u001b[A\n",
      "  4%|▍         | 11/287 [00:18<07:43,  1.68s/it]\u001b[A\n",
      "  4%|▍         | 12/287 [00:20<07:39,  1.67s/it]\u001b[A\n",
      "  5%|▍         | 13/287 [00:21<07:36,  1.67s/it]\u001b[A\n",
      "  5%|▍         | 14/287 [00:23<07:33,  1.66s/it]\u001b[A\n",
      "  5%|▌         | 15/287 [00:25<07:32,  1.66s/it]\u001b[A\n",
      "  6%|▌         | 16/287 [00:26<07:30,  1.66s/it]\u001b[A\n",
      "  6%|▌         | 17/287 [00:28<07:28,  1.66s/it]\u001b[A\n",
      "  6%|▋         | 18/287 [00:30<07:26,  1.66s/it]\u001b[A\n",
      "  7%|▋         | 19/287 [00:31<07:24,  1.66s/it]\u001b[A\n",
      "  7%|▋         | 20/287 [00:33<07:24,  1.66s/it]\u001b[A\n",
      "  7%|▋         | 21/287 [00:35<07:21,  1.66s/it]\u001b[A\n",
      "  8%|▊         | 22/287 [00:36<07:23,  1.67s/it]\u001b[A\n",
      "  8%|▊         | 23/287 [00:38<07:19,  1.67s/it]\u001b[A\n",
      "  8%|▊         | 24/287 [00:40<07:17,  1.66s/it]\u001b[A\n",
      "  9%|▊         | 25/287 [00:41<07:15,  1.66s/it]\u001b[A\n",
      "  9%|▉         | 26/287 [00:43<07:14,  1.67s/it]\u001b[A\n",
      "  9%|▉         | 27/287 [00:45<07:13,  1.67s/it]\u001b[A\n",
      " 10%|▉         | 28/287 [00:46<07:12,  1.67s/it]\u001b[A\n",
      " 10%|█         | 29/287 [00:48<07:10,  1.67s/it]\u001b[A\n",
      " 10%|█         | 30/287 [00:50<07:09,  1.67s/it]\u001b[A\n",
      " 11%|█         | 31/287 [00:51<07:07,  1.67s/it]\u001b[A\n",
      " 11%|█         | 32/287 [00:53<07:06,  1.67s/it]\u001b[A\n",
      " 11%|█▏        | 33/287 [00:55<07:05,  1.68s/it]\u001b[A\n",
      " 12%|█▏        | 34/287 [00:57<07:05,  1.68s/it]\u001b[A\n",
      " 12%|█▏        | 35/287 [00:58<07:04,  1.68s/it]\u001b[A\n",
      " 13%|█▎        | 36/287 [01:00<07:02,  1.68s/it]\u001b[A\n",
      " 13%|█▎        | 37/287 [01:02<07:01,  1.69s/it]\u001b[A\n",
      " 13%|█▎        | 38/287 [01:03<07:02,  1.70s/it]\u001b[A\n",
      " 14%|█▎        | 39/287 [01:05<06:59,  1.69s/it]\u001b[A\n",
      " 14%|█▍        | 40/287 [01:07<07:00,  1.70s/it]\u001b[A\n",
      " 14%|█▍        | 41/287 [01:08<06:56,  1.69s/it]\u001b[A\n",
      " 15%|█▍        | 42/287 [01:10<06:58,  1.71s/it]\u001b[A\n",
      " 15%|█▍        | 43/287 [01:12<06:58,  1.71s/it]\u001b[A\n",
      " 15%|█▌        | 44/287 [01:14<06:55,  1.71s/it]\u001b[A\n",
      " 16%|█▌        | 45/287 [01:15<06:53,  1.71s/it]\u001b[A\n",
      " 16%|█▌        | 46/287 [01:17<06:51,  1.71s/it]\u001b[A\n",
      " 16%|█▋        | 47/287 [01:19<06:47,  1.70s/it]\u001b[A\n",
      " 17%|█▋        | 48/287 [01:20<06:45,  1.70s/it]\u001b[A\n",
      " 17%|█▋        | 49/287 [01:22<06:41,  1.69s/it]\u001b[A\n",
      " 17%|█▋        | 50/287 [01:24<06:40,  1.69s/it]\u001b[A\n",
      " 18%|█▊        | 51/287 [01:25<06:39,  1.69s/it]\u001b[A\n",
      " 18%|█▊        | 52/287 [01:27<06:38,  1.69s/it]\u001b[A\n",
      " 18%|█▊        | 53/287 [01:29<06:36,  1.69s/it]\u001b[A\n",
      " 19%|█▉        | 54/287 [01:30<06:34,  1.69s/it]\u001b[A\n",
      " 19%|█▉        | 55/287 [01:32<06:32,  1.69s/it]\u001b[A\n",
      " 20%|█▉        | 56/287 [01:34<06:30,  1.69s/it]\u001b[A\n",
      " 20%|█▉        | 57/287 [01:36<06:28,  1.69s/it]\u001b[A\n",
      " 20%|██        | 58/287 [01:37<06:26,  1.69s/it]\u001b[A\n",
      " 21%|██        | 59/287 [01:39<06:24,  1.69s/it]\u001b[A\n",
      " 21%|██        | 60/287 [01:41<06:23,  1.69s/it]\u001b[A\n",
      " 21%|██▏       | 61/287 [01:42<06:21,  1.69s/it]\u001b[A\n",
      " 22%|██▏       | 62/287 [01:44<06:19,  1.69s/it]\u001b[A\n",
      " 22%|██▏       | 63/287 [01:46<06:17,  1.68s/it]\u001b[A\n",
      " 22%|██▏       | 64/287 [01:47<06:26,  1.73s/it]\u001b[A\n",
      " 23%|██▎       | 65/287 [01:49<06:23,  1.73s/it]\u001b[A\n",
      " 23%|██▎       | 66/287 [01:51<06:17,  1.71s/it]\u001b[A\n",
      " 23%|██▎       | 67/287 [01:53<06:14,  1.70s/it]\u001b[A\n",
      " 24%|██▎       | 68/287 [01:54<06:12,  1.70s/it]\u001b[A\n",
      " 24%|██▍       | 69/287 [01:56<06:12,  1.71s/it]\u001b[A\n",
      " 24%|██▍       | 70/287 [01:58<06:09,  1.70s/it]\u001b[A\n",
      " 25%|██▍       | 71/287 [01:59<06:05,  1.69s/it]\u001b[A\n",
      " 25%|██▌       | 72/287 [02:01<06:03,  1.69s/it]\u001b[A\n",
      " 25%|██▌       | 73/287 [02:03<06:01,  1.69s/it]\u001b[A\n",
      " 26%|██▌       | 74/287 [02:04<05:59,  1.69s/it]\u001b[A\n",
      " 26%|██▌       | 75/287 [02:06<05:57,  1.68s/it]\u001b[A\n",
      " 26%|██▋       | 76/287 [02:08<05:56,  1.69s/it]\u001b[A\n",
      " 27%|██▋       | 77/287 [02:09<05:54,  1.69s/it]\u001b[A\n",
      " 27%|██▋       | 78/287 [02:11<05:51,  1.68s/it]\u001b[A\n",
      " 28%|██▊       | 79/287 [02:13<05:50,  1.69s/it]\u001b[A\n",
      " 28%|██▊       | 80/287 [02:15<05:49,  1.69s/it]\u001b[A\n",
      " 28%|██▊       | 81/287 [02:16<05:46,  1.68s/it]\u001b[A\n",
      " 29%|██▊       | 82/287 [02:18<05:44,  1.68s/it]\u001b[A\n",
      " 29%|██▉       | 83/287 [02:20<05:41,  1.67s/it]\u001b[A\n",
      " 29%|██▉       | 84/287 [02:21<05:40,  1.68s/it]\u001b[A\n",
      " 30%|██▉       | 85/287 [02:23<05:38,  1.68s/it]\u001b[A\n",
      " 30%|██▉       | 86/287 [02:25<05:37,  1.68s/it]\u001b[A\n",
      " 30%|███       | 87/287 [02:26<05:36,  1.68s/it]\u001b[A\n",
      " 31%|███       | 88/287 [02:28<05:34,  1.68s/it]\u001b[A\n",
      " 31%|███       | 89/287 [02:30<05:33,  1.69s/it]\u001b[A\n",
      " 31%|███▏      | 90/287 [02:31<05:32,  1.69s/it]\u001b[A\n",
      " 32%|███▏      | 91/287 [02:33<05:31,  1.69s/it]\u001b[A\n",
      " 32%|███▏      | 92/287 [02:35<05:30,  1.69s/it]\u001b[A\n",
      " 32%|███▏      | 93/287 [02:36<05:29,  1.70s/it]\u001b[A\n",
      " 33%|███▎      | 94/287 [02:38<05:27,  1.70s/it]\u001b[A\n",
      " 33%|███▎      | 95/287 [02:40<05:24,  1.69s/it]\u001b[A\n",
      " 33%|███▎      | 96/287 [02:41<05:21,  1.68s/it]\u001b[A\n",
      " 34%|███▍      | 97/287 [02:43<05:19,  1.68s/it]\u001b[A\n",
      " 34%|███▍      | 98/287 [02:45<05:18,  1.69s/it]\u001b[A\n",
      " 34%|███▍      | 99/287 [02:47<05:16,  1.68s/it]\u001b[A\n",
      " 35%|███▍      | 100/287 [02:48<05:13,  1.68s/it]\u001b[A\n",
      " 35%|███▌      | 101/287 [02:50<05:12,  1.68s/it]\u001b[A\n",
      " 36%|███▌      | 102/287 [02:52<05:10,  1.68s/it]\u001b[A\n",
      " 36%|███▌      | 103/287 [02:53<05:08,  1.68s/it]\u001b[A\n",
      " 36%|███▌      | 104/287 [02:55<05:06,  1.68s/it]\u001b[A\n",
      " 37%|███▋      | 105/287 [02:57<05:04,  1.68s/it]\u001b[A\n",
      " 37%|███▋      | 106/287 [02:58<05:03,  1.67s/it]\u001b[A\n",
      " 37%|███▋      | 107/287 [03:00<05:01,  1.67s/it]\u001b[A\n",
      " 38%|███▊      | 108/287 [03:02<04:59,  1.67s/it]\u001b[A\n",
      " 38%|███▊      | 109/287 [03:03<04:58,  1.68s/it]\u001b[A\n",
      " 38%|███▊      | 110/287 [03:05<04:56,  1.67s/it]\u001b[A\n",
      " 39%|███▊      | 111/287 [03:07<04:54,  1.67s/it]\u001b[A\n",
      " 39%|███▉      | 112/287 [03:08<04:51,  1.67s/it]\u001b[A\n",
      " 39%|███▉      | 113/287 [03:10<04:48,  1.66s/it]\u001b[A\n",
      " 40%|███▉      | 114/287 [03:12<04:46,  1.65s/it]\u001b[A\n",
      " 40%|████      | 115/287 [03:13<04:44,  1.66s/it]\u001b[A\n",
      " 40%|████      | 116/287 [03:15<04:43,  1.66s/it]\u001b[A\n",
      " 41%|████      | 117/287 [03:17<04:42,  1.66s/it]\u001b[A\n",
      " 41%|████      | 118/287 [03:18<04:40,  1.66s/it]\u001b[A\n",
      " 41%|████▏     | 119/287 [03:20<04:39,  1.66s/it]\u001b[A\n",
      " 42%|████▏     | 120/287 [03:22<04:38,  1.67s/it]\u001b[A\n",
      " 42%|████▏     | 121/287 [03:23<04:36,  1.67s/it]\u001b[A\n",
      " 43%|████▎     | 122/287 [03:25<04:34,  1.66s/it]\u001b[A\n",
      " 43%|████▎     | 123/287 [03:27<04:33,  1.67s/it]\u001b[A\n",
      " 43%|████▎     | 124/287 [03:28<04:31,  1.67s/it]\u001b[A\n",
      " 44%|████▎     | 125/287 [03:30<04:30,  1.67s/it]\u001b[A\n",
      " 44%|████▍     | 126/287 [03:32<04:28,  1.67s/it]\u001b[A\n",
      " 44%|████▍     | 127/287 [03:33<04:27,  1.67s/it]\u001b[A\n",
      " 45%|████▍     | 128/287 [03:35<04:24,  1.67s/it]\u001b[A\n",
      " 45%|████▍     | 129/287 [03:37<04:23,  1.67s/it]\u001b[A\n",
      " 45%|████▌     | 130/287 [03:38<04:21,  1.66s/it]\u001b[A\n",
      " 46%|████▌     | 131/287 [03:40<04:19,  1.67s/it]\u001b[A\n",
      " 46%|████▌     | 132/287 [03:42<04:17,  1.66s/it]\u001b[A\n",
      " 46%|████▋     | 133/287 [03:43<04:15,  1.66s/it]\u001b[A\n",
      " 47%|████▋     | 134/287 [03:45<04:13,  1.66s/it]\u001b[A\n",
      " 47%|████▋     | 135/287 [03:47<04:18,  1.70s/it]\u001b[A\n",
      " 47%|████▋     | 136/287 [03:48<04:17,  1.70s/it]\u001b[A\n",
      " 48%|████▊     | 137/287 [03:50<04:13,  1.69s/it]\u001b[A\n",
      " 48%|████▊     | 138/287 [03:52<04:11,  1.69s/it]\u001b[A\n",
      " 48%|████▊     | 139/287 [03:53<04:09,  1.68s/it]\u001b[A\n",
      " 49%|████▉     | 140/287 [03:55<04:07,  1.68s/it]\u001b[A\n",
      " 49%|████▉     | 141/287 [03:57<04:05,  1.68s/it]\u001b[A\n",
      " 49%|████▉     | 142/287 [03:58<04:03,  1.68s/it]\u001b[A\n",
      " 50%|████▉     | 143/287 [04:00<04:01,  1.68s/it]\u001b[A\n",
      " 50%|█████     | 144/287 [04:02<04:00,  1.68s/it]\u001b[A\n",
      " 51%|█████     | 145/287 [04:03<03:59,  1.69s/it]\u001b[A\n",
      " 51%|█████     | 146/287 [04:05<03:59,  1.70s/it]\u001b[A\n",
      " 51%|█████     | 147/287 [04:07<03:58,  1.71s/it]\u001b[A\n",
      " 52%|█████▏    | 148/287 [04:09<03:56,  1.70s/it]\u001b[A\n",
      " 52%|█████▏    | 149/287 [04:10<03:54,  1.70s/it]\u001b[A\n",
      " 52%|█████▏    | 150/287 [04:12<03:53,  1.70s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 151/287 [04:14<03:51,  1.70s/it]\u001b[A\n",
      " 53%|█████▎    | 152/287 [04:15<03:51,  1.71s/it]\u001b[A\n",
      " 53%|█████▎    | 153/287 [04:17<03:47,  1.70s/it]\u001b[A\n",
      " 54%|█████▎    | 154/287 [04:19<03:44,  1.69s/it]\u001b[A\n",
      " 54%|█████▍    | 155/287 [04:20<03:41,  1.68s/it]\u001b[A\n",
      " 54%|█████▍    | 156/287 [04:22<03:40,  1.68s/it]\u001b[A\n",
      " 55%|█████▍    | 157/287 [04:24<03:38,  1.68s/it]\u001b[A\n",
      " 55%|█████▌    | 158/287 [04:25<03:36,  1.68s/it]\u001b[A\n",
      " 55%|█████▌    | 159/287 [04:27<03:34,  1.68s/it]\u001b[A\n",
      " 56%|█████▌    | 160/287 [04:29<03:34,  1.69s/it]\u001b[A\n",
      " 56%|█████▌    | 161/287 [04:31<03:33,  1.70s/it]\u001b[A\n",
      " 56%|█████▋    | 162/287 [04:32<03:31,  1.69s/it]\u001b[A\n",
      " 57%|█████▋    | 163/287 [04:34<03:30,  1.69s/it]\u001b[A\n",
      " 57%|█████▋    | 164/287 [04:36<03:27,  1.69s/it]\u001b[A\n",
      " 57%|█████▋    | 165/287 [04:37<03:25,  1.69s/it]\u001b[A\n",
      " 58%|█████▊    | 166/287 [04:39<03:23,  1.68s/it]\u001b[A\n",
      " 58%|█████▊    | 167/287 [04:41<03:21,  1.68s/it]\u001b[A\n",
      " 59%|█████▊    | 168/287 [04:42<03:19,  1.68s/it]\u001b[A\n",
      " 59%|█████▉    | 169/287 [04:44<03:17,  1.67s/it]\u001b[A\n",
      " 59%|█████▉    | 170/287 [04:46<03:15,  1.67s/it]\u001b[A\n",
      " 60%|█████▉    | 171/287 [04:47<03:12,  1.66s/it]\u001b[A\n",
      " 60%|█████▉    | 172/287 [04:49<03:10,  1.65s/it]\u001b[A\n",
      " 60%|██████    | 173/287 [04:51<03:08,  1.65s/it]\u001b[A\n",
      " 61%|██████    | 174/287 [04:52<03:06,  1.65s/it]\u001b[A\n",
      " 61%|██████    | 175/287 [04:54<03:05,  1.65s/it]\u001b[A\n",
      " 61%|██████▏   | 176/287 [04:56<03:03,  1.65s/it]\u001b[A\n",
      " 62%|██████▏   | 177/287 [04:57<03:01,  1.65s/it]\u001b[A\n",
      " 62%|██████▏   | 178/287 [04:59<03:00,  1.66s/it]\u001b[A\n",
      " 62%|██████▏   | 179/287 [05:01<02:59,  1.66s/it]\u001b[A\n",
      " 63%|██████▎   | 180/287 [05:02<02:57,  1.66s/it]\u001b[A\n",
      " 63%|██████▎   | 181/287 [05:04<02:56,  1.66s/it]\u001b[A\n",
      " 63%|██████▎   | 182/287 [05:06<02:54,  1.67s/it]\u001b[A\n",
      " 64%|██████▍   | 183/287 [05:07<02:53,  1.67s/it]\u001b[A\n",
      " 64%|██████▍   | 184/287 [05:09<02:51,  1.67s/it]\u001b[A\n",
      " 64%|██████▍   | 185/287 [05:11<02:49,  1.67s/it]\u001b[A\n",
      " 65%|██████▍   | 186/287 [05:12<02:48,  1.66s/it]\u001b[A\n",
      " 65%|██████▌   | 187/287 [05:14<02:46,  1.67s/it]\u001b[A\n",
      " 66%|██████▌   | 188/287 [05:16<02:44,  1.67s/it]\u001b[A\n",
      " 66%|██████▌   | 189/287 [05:17<02:43,  1.66s/it]\u001b[A\n",
      " 66%|██████▌   | 190/287 [05:19<02:41,  1.67s/it]\u001b[A\n",
      " 67%|██████▋   | 191/287 [05:21<02:39,  1.67s/it]\u001b[A\n",
      " 67%|██████▋   | 192/287 [05:22<02:38,  1.67s/it]\u001b[A\n",
      " 67%|██████▋   | 193/287 [05:24<02:37,  1.68s/it]\u001b[A\n",
      " 68%|██████▊   | 194/287 [05:26<02:35,  1.67s/it]\u001b[A\n",
      " 68%|██████▊   | 195/287 [05:27<02:33,  1.67s/it]\u001b[A\n",
      " 68%|██████▊   | 196/287 [05:29<02:31,  1.67s/it]\u001b[A\n",
      " 69%|██████▊   | 197/287 [05:31<02:30,  1.67s/it]\u001b[A\n",
      " 69%|██████▉   | 198/287 [05:32<02:28,  1.67s/it]\u001b[A\n",
      " 69%|██████▉   | 199/287 [05:34<02:31,  1.72s/it]\u001b[A\n",
      " 70%|██████▉   | 200/287 [05:36<02:28,  1.71s/it]\u001b[A\n",
      " 70%|███████   | 201/287 [05:37<02:28,  1.73s/it]\u001b[A\n",
      " 70%|███████   | 202/287 [05:40<02:35,  1.83s/it]\u001b[A\n",
      " 71%|███████   | 203/287 [05:42<02:36,  1.87s/it]\u001b[A\n",
      " 71%|███████   | 204/287 [05:43<02:30,  1.81s/it]\u001b[A\n",
      " 71%|███████▏  | 205/287 [05:45<02:25,  1.78s/it]\u001b[A\n",
      " 72%|███████▏  | 206/287 [05:47<02:25,  1.79s/it]\u001b[A\n",
      " 72%|███████▏  | 207/287 [05:48<02:21,  1.77s/it]\u001b[A\n",
      " 72%|███████▏  | 208/287 [05:50<02:17,  1.74s/it]\u001b[A\n",
      " 73%|███████▎  | 209/287 [05:52<02:14,  1.72s/it]\u001b[A\n",
      " 73%|███████▎  | 210/287 [05:53<02:11,  1.71s/it]\u001b[A\n",
      " 74%|███████▎  | 211/287 [05:55<02:10,  1.72s/it]\u001b[A\n",
      " 74%|███████▍  | 212/287 [05:57<02:08,  1.71s/it]\u001b[A\n",
      " 74%|███████▍  | 213/287 [05:59<02:15,  1.83s/it]\u001b[A\n",
      " 75%|███████▍  | 214/287 [06:01<02:12,  1.81s/it]\u001b[A\n",
      " 75%|███████▍  | 215/287 [06:03<02:09,  1.80s/it]\u001b[A\n",
      " 75%|███████▌  | 216/287 [06:04<02:06,  1.78s/it]\u001b[A\n",
      " 76%|███████▌  | 217/287 [06:06<02:04,  1.77s/it]\u001b[A\n",
      " 76%|███████▌  | 218/287 [06:08<02:01,  1.77s/it]\u001b[A\n",
      " 76%|███████▋  | 219/287 [06:09<01:58,  1.75s/it]\u001b[A\n",
      " 77%|███████▋  | 220/287 [06:11<01:55,  1.73s/it]\u001b[A\n",
      " 77%|███████▋  | 221/287 [06:13<01:53,  1.71s/it]\u001b[A\n",
      " 77%|███████▋  | 222/287 [06:15<01:50,  1.71s/it]\u001b[A\n",
      " 78%|███████▊  | 223/287 [06:16<01:48,  1.70s/it]\u001b[A\n",
      " 78%|███████▊  | 224/287 [06:18<01:46,  1.69s/it]\u001b[A\n",
      " 78%|███████▊  | 225/287 [06:20<01:44,  1.69s/it]\u001b[A\n",
      " 79%|███████▊  | 226/287 [06:21<01:43,  1.69s/it]\u001b[A\n",
      " 79%|███████▉  | 227/287 [06:23<01:41,  1.69s/it]\u001b[A\n",
      " 79%|███████▉  | 228/287 [06:25<01:39,  1.69s/it]\u001b[A\n",
      " 80%|███████▉  | 229/287 [06:26<01:37,  1.69s/it]\u001b[A\n",
      " 80%|████████  | 230/287 [06:28<01:36,  1.69s/it]\u001b[A\n",
      " 80%|████████  | 231/287 [06:30<01:34,  1.69s/it]\u001b[A\n",
      " 81%|████████  | 232/287 [06:31<01:33,  1.70s/it]\u001b[A\n",
      " 81%|████████  | 233/287 [06:33<01:31,  1.70s/it]\u001b[A\n",
      " 82%|████████▏ | 234/287 [06:35<01:29,  1.70s/it]\u001b[A\n",
      " 82%|████████▏ | 235/287 [06:37<01:28,  1.70s/it]\u001b[A\n",
      " 82%|████████▏ | 236/287 [06:38<01:26,  1.70s/it]\u001b[A\n",
      " 83%|████████▎ | 237/287 [06:40<01:24,  1.69s/it]\u001b[A\n",
      " 83%|████████▎ | 238/287 [06:42<01:22,  1.69s/it]\u001b[A\n",
      " 83%|████████▎ | 239/287 [06:43<01:21,  1.69s/it]\u001b[A\n",
      " 84%|████████▎ | 240/287 [06:45<01:19,  1.69s/it]\u001b[A\n",
      " 84%|████████▍ | 241/287 [06:47<01:17,  1.70s/it]\u001b[A\n",
      " 84%|████████▍ | 242/287 [06:49<01:18,  1.74s/it]\u001b[A\n",
      " 85%|████████▍ | 243/287 [06:50<01:16,  1.73s/it]\u001b[A\n",
      " 85%|████████▌ | 244/287 [06:52<01:14,  1.74s/it]\u001b[A\n",
      " 85%|████████▌ | 245/287 [06:54<01:13,  1.74s/it]\u001b[A\n",
      " 86%|████████▌ | 246/287 [06:56<01:11,  1.75s/it]\u001b[A\n",
      " 86%|████████▌ | 247/287 [06:57<01:10,  1.76s/it]\u001b[A\n",
      " 86%|████████▋ | 248/287 [06:59<01:09,  1.78s/it]\u001b[A\n",
      " 87%|████████▋ | 249/287 [07:01<01:07,  1.79s/it]\u001b[A\n",
      " 87%|████████▋ | 250/287 [07:03<01:06,  1.79s/it]\u001b[A\n",
      " 87%|████████▋ | 251/287 [07:05<01:04,  1.79s/it]\u001b[A\n",
      " 88%|████████▊ | 252/287 [07:06<01:01,  1.75s/it]\u001b[A\n",
      " 88%|████████▊ | 253/287 [07:08<00:59,  1.74s/it]\u001b[A\n",
      " 89%|████████▊ | 254/287 [07:10<00:56,  1.72s/it]\u001b[A\n",
      " 89%|████████▉ | 255/287 [07:11<00:54,  1.71s/it]\u001b[A\n",
      " 89%|████████▉ | 256/287 [07:13<00:52,  1.71s/it]\u001b[A\n",
      " 90%|████████▉ | 257/287 [07:15<00:50,  1.70s/it]\u001b[A\n",
      " 90%|████████▉ | 258/287 [07:16<00:49,  1.69s/it]\u001b[A\n",
      " 90%|█████████ | 259/287 [07:18<00:47,  1.69s/it]\u001b[A\n",
      " 91%|█████████ | 260/287 [07:20<00:45,  1.69s/it]\u001b[A\n",
      " 91%|█████████ | 261/287 [07:21<00:44,  1.70s/it]\u001b[A\n",
      " 91%|█████████▏| 262/287 [07:23<00:42,  1.69s/it]\u001b[A\n",
      " 92%|█████████▏| 263/287 [07:25<00:40,  1.69s/it]\u001b[A\n",
      " 92%|█████████▏| 264/287 [07:26<00:38,  1.69s/it]\u001b[A\n",
      " 92%|█████████▏| 265/287 [07:28<00:37,  1.69s/it]\u001b[A\n",
      " 93%|█████████▎| 266/287 [07:30<00:36,  1.72s/it]\u001b[A\n",
      " 93%|█████████▎| 267/287 [07:32<00:35,  1.80s/it]\u001b[A\n",
      " 93%|█████████▎| 268/287 [07:34<00:34,  1.80s/it]\u001b[A\n",
      " 94%|█████████▎| 269/287 [07:36<00:32,  1.81s/it]\u001b[A\n",
      " 94%|█████████▍| 270/287 [07:37<00:30,  1.79s/it]\u001b[A\n",
      " 94%|█████████▍| 271/287 [07:39<00:28,  1.76s/it]\u001b[A\n",
      " 95%|█████████▍| 272/287 [07:41<00:26,  1.74s/it]\u001b[A\n",
      " 95%|█████████▌| 273/287 [07:42<00:24,  1.74s/it]\u001b[A\n",
      " 95%|█████████▌| 274/287 [07:44<00:22,  1.72s/it]\u001b[A\n",
      " 96%|█████████▌| 275/287 [07:46<00:20,  1.74s/it]\u001b[A\n",
      " 96%|█████████▌| 276/287 [07:48<00:19,  1.78s/it]\u001b[A\n",
      " 97%|█████████▋| 277/287 [07:49<00:17,  1.76s/it]\u001b[A\n",
      " 97%|█████████▋| 278/287 [07:51<00:15,  1.74s/it]\u001b[A\n",
      " 97%|█████████▋| 279/287 [07:53<00:13,  1.73s/it]\u001b[A\n",
      " 98%|█████████▊| 280/287 [07:55<00:12,  1.73s/it]\u001b[A\n",
      " 98%|█████████▊| 281/287 [07:56<00:10,  1.73s/it]\u001b[A\n",
      " 98%|█████████▊| 282/287 [07:58<00:08,  1.71s/it]\u001b[A\n",
      " 99%|█████████▊| 283/287 [08:00<00:06,  1.71s/it]\u001b[A\n",
      " 99%|█████████▉| 284/287 [08:01<00:05,  1.70s/it]\u001b[A\n",
      " 99%|█████████▉| 285/287 [08:03<00:03,  1.70s/it]\u001b[A\n",
      "100%|█████████▉| 286/287 [08:05<00:01,  1.70s/it]\u001b[A\n",
      "100%|██████████| 287/287 [08:07<00:00,  1.70s/it]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9878048780487805"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare to model created by original user\n",
    "from models import ConvNet\n",
    "downsampling = 1\n",
    "competitivemodel = ConvNet(64, 7)\n",
    "competitivemodel.load_state_dict(torch.load(\"models/original/max_pooling__n_layers=7__n_filters=64__downsampling=1__n_seconds=3.torch\", map_location=torch.device('cpu')))\n",
    "competitivemodel.double()\n",
    "evaluate(competitivemodel, testloader, preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
